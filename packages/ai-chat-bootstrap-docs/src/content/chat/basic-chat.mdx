---
title: Basic Chat
description: The minimal setup for getting started with AI chat interfaces, including frontend and backend examples.
---

import { BasicChatExample, BASIC_CHAT_SOURCE, BASIC_CHAT_API_SOURCE } from "../../components/BasicChatExample";
import { LiveCodeExample } from "../../components/LiveCodeExample";
import { Api as API } from "../../components/ApiLink";

# Basic Chat

This example shows the **minimal setup** needed for an AI chat interface. The demo uses mocked responses, but the code examples show real implementation patterns.

<LiveCodeExample code={BASIC_CHAT_SOURCE}>
  <BasicChatExample />
</LiveCodeExample>

## Frontend Implementation

The frontend uses the `ChatContainer` component which handles all message state, streaming, and API communication internally:

```tsx
import React from "react";
import { ChatContainer } from "ai-chat-bootstrap";

export function BasicChat() {
  return (
    <div className="h-[600px] w-full">
      <ChatContainer
        transport={{ api: "/api/chat" }}
        messages={{ systemPrompt: "You are a helpful AI assistant." }}
        header={{ title: "AI Assistant", subtitle: "Connected to AI" }}
        ui={{ placeholder: "Ask me anything..." }}
      />
    </div>
  );
}
```

## Backend API Route

Create an API route at `app/api/chat/route.ts` using the new server template:

```ts
import { createAIChatHandler } from "ai-chat-bootstrap/server";
import { openai } from "@ai-sdk/openai";

const handler = createAIChatHandler({
  model: openai("gpt-4"),
  streamOptions: { temperature: 0.7 },
});

export { handler as POST };
```

Or with Azure OpenAI:

```ts
import { createAIChatHandler } from "ai-chat-bootstrap/server";
import { createAzure } from "@ai-sdk/azure";

const azure = createAzure({
  resourceName: process.env.AZURE_RESOURCE_NAME!,
  apiKey: process.env.AZURE_API_KEY!,
});

const handler = createAIChatHandler({
  model: azure("gpt-4"),
  streamOptions: { temperature: 0.7 },
});

export { handler as POST };
```

> Note: The `useAIChat` hook automatically sends an `enrichedSystemPrompt` containing a standardized preamble plus conditional sections (Tools / Context / Focus) and then appends your `systemPrompt` (if provided). Always prefer `enrichedSystemPrompt` when present and do not rebuild those sections again on the server.

## How it works

1. **Frontend**: The `ChatContainer` component manages message state and automatically posts to `/api/chat`
2. **Backend**: The API route receives messages and streams responses using the Vercel AI SDK
3. **Streaming**: Responses are streamed back to the frontend and rendered in real-time
4. **State Management**: All message history and loading states are handled automatically

## Next steps

- **Add tools**: Register frontend tools (or MCP servers) and they are automatically merged into the handler request
- **Add context**: Use <API name="useAIContext">useAIContext</API> to share app state with the AI
- **Add suggestions**: Enable contextual suggestions with `enableSuggestions={true}`
- **Style**: Customize appearance via Tailwind classes or component props

## API Reference

- Hook: [useAIChat](/api/hooks/use-ai-chat)

## Next

Continue to [Popout Chat â†’](/chat/chat-popout)
